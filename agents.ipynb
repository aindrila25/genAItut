{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGroq(model =\"llama3-groq-8b-8192-tool-use-preview\")\n",
    "# wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "# arxiv = ArxivAPIWrapper()\n",
    "tools = load_tools([\"arxiv\",\"wikipedia\"])\n",
    "#tools = [wikipedia]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [SystemMessage(content='You are a helpful assistant that takes an arxiv paper code and simplifies it to give an explanation quoting articles from wikipedia for the more complicated terms', additional_kwargs={}, response_metadata={}, id='1a6aeffe-cc0c-43de-870c-9951cedd96f1'),\n",
       "  HumanMessage(content='The arxiv paper code is 1605.08386', additional_kwargs={}, response_metadata={}, id='429e69ab-36a2-499b-a10c-e41933451f1a'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9zdm', 'function': {'arguments': '{\"query\": \"1605.08386\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_t8k4', 'function': {'arguments': '{\"query\": \"Gaussian process\"}', 'name': 'wikipedia'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 388, 'total_tokens': 446, 'completion_time': 0.053250022, 'prompt_time': 0.052435353, 'queue_time': 0.0011424959999999998, 'total_time': 0.105685375}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6cd9766d-2a64-43bb-aa68-688a918e920b-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '1605.08386'}, 'id': 'call_9zdm', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Gaussian process'}, 'id': 'call_t8k4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 388, 'output_tokens': 58, 'total_tokens': 446}),\n",
       "  ToolMessage(content='Published: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.', name='arxiv', id='3a3b3d23-8b73-4db0-844b-e45555ba05c8', tool_call_id='call_9zdm'),\n",
       "  ToolMessage(content='Page: Gaussian process\\nSummary: In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.\\nThe concept of Gaussian processes is named after Carl Friedrich Gauss because it is based on the notion of the Gaussian distribution (normal distribution). Gaussian processes can be seen as an infinite-dimensional generalization of multivariate normal distributions.\\nGaussian processes are useful in statistical modelling, benefiting from properties inherited from the normal distribution. For example, if a random process is modelled as a Gaussian process, the distributions of various derived quantities can be obtained explicitly. Such quantities include the average value of the process over a range of times and the error in estimating the average using sample values at a small set of times. While exact models often scale poorly as the amount of data increases, multiple approximation methods have been developed which often retain good accuracy while drastically reducing computation time.\\n\\n\\n\\nPage: Gaussian process approximations\\nSummary: In statistics and machine learning, Gaussian process approximation is a computational method that accelerates inference tasks in the context of a Gaussian process model, most commonly likelihood evaluation and prediction. Like approximations of other models, they can often be expressed as additional assumptions imposed on the model, which do not correspond to any actual feature, but which retain its key properties while simplifying calculations. Many of these approximation methods can be expressed in purely linear algebraic or functional analytic terms as matrix or function approximations. Others are purely algorithmic and cannot easily be rephrased as a modification of a statistical model.\\n\\nPage: Neural network Gaussian process\\nSummary: A Neural Network Gaussian Process (NNGP) is a Gaussian process (GP) obtained as the limit of a certain type of sequence of neural networks. Specifically, a wide variety of network architectures converges to a GP in the infinitely wide limit, in the sense of distribution.\\nThe concept constitutes an intensional definition, i.e., a NNGP is just a GP, but distinguished by how it is obtained.\\n\\n', name='wikipedia', id='8449e684-2765-4c53-a099-9140d06c9701', tool_call_id='call_t8k4'),\n",
       "  AIMessage(content=\"The arxiv paper with code 1605.08386 discusses Heat-bath random walks on graphs. It's a complex topic, but essentially, it involves studying graphs and their mixing behavior using random walks. For a deeper understanding of Gaussian processes, which are mentioned in the paper, Wikipedia provides a detailed explanation. It describes Gaussian processes as stochastic processes with a multivariate normal distribution, useful in statistical modelling and machine learning. There's also a section on Gaussian process approximations and Neural Network Gaussian Processes, which are interesting concepts related to how we can simplify and work with these complex processes.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 1092, 'total_tokens': 1211, 'completion_time': 0.110420266, 'prompt_time': 0.145624314, 'queue_time': 0.0012760249999999862, 'total_time': 0.25604458}, 'model_name': 'llama3-groq-8b-8192-tool-use-preview', 'system_fingerprint': 'fp_260dc69250', 'finish_reason': 'stop', 'logprobs': None}, id='run-b5ac960d-51d7-4093-93ad-9b80cbf288f4-0', usage_metadata={'input_tokens': 1092, 'output_tokens': 119, 'total_tokens': 1211})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant that takes an arxiv paper code and simplifies it to give an explanation quoting articles from wikipedia for the more complicated terms\" ),\n",
    "        (\"human\",\"The arxiv paper code is {code}\")\n",
    "    ]\n",
    ")\n",
    "agent = create_react_agent(\n",
    "    llm , tools\n",
    ")\n",
    "initial_messages = prompt.invoke({\"code\":\"1605.08386\"}).to_messages()\n",
    "messages=agent.invoke(input={\"messages\": initial_messages})\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The arxiv paper with code 1605.08386 discusses Heat-bath random walks on graphs. It's a complex topic, but essentially, it involves studying graphs and their mixing behavior using random walks. For a deeper understanding of Gaussian processes, which are mentioned in the paper, Wikipedia provides a detailed explanation. It describes Gaussian processes as stochastic processes with a multivariate normal distribution, useful in statistical modelling and machine learning. There's also a section on Gaussian process approximations and Neural Network Gaussian Processes, which are interesting concepts related to how we can simplify and work with these complex processes.\n"
     ]
    }
   ],
   "source": [
    "print(messages[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
